diff --git a/.idea/GFML.iml b/.idea/GFML.iml
index 8b8c395..6cc4ddb 100644
--- a/.idea/GFML.iml
+++ b/.idea/GFML.iml
@@ -2,7 +2,7 @@
 <module type="PYTHON_MODULE" version="4">
   <component name="NewModuleRootManager">
     <content url="file://$MODULE_DIR$" />
-    <orderEntry type="inheritedJdk" />
+    <orderEntry type="jdk" jdkName="Python 3.7 (mcl)" jdkType="Python SDK" />
     <orderEntry type="sourceFolder" forTests="false" />
   </component>
   <component name="PyDocumentationSettings">
diff --git a/.idea/misc.xml b/.idea/misc.xml
index d1e22ec..63eddde 100644
--- a/.idea/misc.xml
+++ b/.idea/misc.xml
@@ -1,4 +1,4 @@
 <?xml version="1.0" encoding="UTF-8"?>
 <project version="4">
-  <component name="ProjectRootManager" version="2" project-jdk-name="Python 3.8" project-jdk-type="Python SDK" />
+  <component name="ProjectRootManager" version="2" project-jdk-name="Python 3.7 (mcl)" project-jdk-type="Python SDK" />
 </project>
\ No newline at end of file
diff --git a/.idea/vcs.xml b/.idea/vcs.xml
index 35eb1dd..c5a681c 100644
--- a/.idea/vcs.xml
+++ b/.idea/vcs.xml
@@ -2,5 +2,6 @@
 <project version="4">
   <component name="VcsDirectoryMappings">
     <mapping directory="" vcs="Git" />
+    <mapping directory="$PROJECT_DIR$/MCL" vcs="Git" />
   </component>
 </project>
\ No newline at end of file
diff --git a/conda-environment.yaml b/conda-environment.yaml
index a732acc..ffe26df 100644
--- a/conda-environment.yaml
+++ b/conda-environment.yaml
@@ -40,7 +40,6 @@ dependencies:
     - gitdb==4.0.9
     - gitpython==3.1.28
     - idna==3.3
-    - imagenetv2-pytorch==0.1
     - ipykernel==6.16.2
     - ipython==8.5.0
     - jedi==0.18.1
@@ -86,10 +85,6 @@ dependencies:
     - smmap==5.0.0
     - stack-data==0.5.1
     - threadpoolctl==3.1.0
-    - torch==1.11.0+cu113
-    - torch-ema==0.3
-    - torchaudio==0.11.0+cu113
-    - torchvision==0.12.0+cu113
     - tornado==6.2
     - tqdm==4.64.0
     - traitlets==5.5.0
diff --git a/gfml-rs/CML.py b/gfml-rs/CML.py
index 45973a5..0aa3d48 100644
--- a/gfml-rs/CML.py
+++ b/gfml-rs/CML.py
@@ -31,41 +31,46 @@ class Multiply(torch.nn.Module):
 
 class CML(torch.nn.Module):
     def __init__(self,
-                 n_users,
-                 n_items,
-                 embed_dim=20,
-                 features=None,
-                 margin=1.5,
-                 master_learning_rate=0.1,
-                 clip_norm=1.0,
-                 hidden_layer_dim=128,
-                 dropout_rate=0.2,
-                 feature_l2_reg=0.1,
-                 feature_projection_scaling_factor=0.5,
-                 use_rank_weight=True,
-                 use_cov_loss=True,
-                 cov_loss_weight=0.1
+                 config,
+                 dataset
                  ):
+        '''
+                         n_users,
+                         n_items,
+                         embed_dim=20,
+                         features=None,
+                         margin=1.5,
+                         master_learning_rate=0.1,
+                         clip_norm=1.0,
+                         hidden_layer_dim=128,
+                         dropout_rate=0.2,
+                         feature_l2_reg=0.1,
+                         feature_projection_scaling_factor=0.5,
+                         use_rank_weight=True,
+                         use_cov_loss=True,
+                         cov_loss_weight=0.1
+         '''
+
         super(CML, self).__init__()
-        self.n_users = n_users
-        self.n_items = n_items
-        self.embed_dim = embed_dim
-
-        self.clip_norm = clip_norm
-        self.margin = margin
-        if features is not None:
-            self.features = features
+        self.n_users = dataset.n_users
+        self.n_items = dataset.n_items
+        self.embed_dim = config['embed_dim']
+
+        self.clip_norm = config['clip_norm']
+        self.margin = config['margin']
+        if config['features'] is not None:
+            self.features = config['features']
         else:
             self.features = None
 
-        self.master_learning_rate = master_learning_rate
-        self.hidden_layer_dim = hidden_layer_dim
-        self.dropout_rate = dropout_rate
-        self.feature_l2_reg = feature_l2_reg
-        self.feature_projection_scaling_factor = feature_projection_scaling_factor
-        self.use_rank_weight = use_rank_weight
-        self.use_cov_loss = use_cov_loss
-        self.cov_loss_weight = cov_loss_weight
+        self.master_learning_rate = config['master_learning_rate']
+        self.hidden_layer_dim = config['hidden_layer_dim']
+        self.dropout_rate = config['dropout_rate']
+        self.feature_l2_reg = config['feature_l2_reg']
+        self.feature_projection_scaling_factor = config['feature_projection_scaling_factor']
+        self.use_rank_weight = config['use_rank_weight']
+        self.use_cov_loss = config['use_cov_loss']
+        self.cov_loss_weight = config['cov_loss_weight']
 
         self.user_positive_items_pairs = None
         self.negative_samples = None
@@ -124,7 +129,6 @@ class CML(torch.nn.Module):
         scores = torch.sum(users_emb*items_emb, dim=1)
         return self.f(scores)
 
-
     def loss(self, user, pos, neg):
         loss_value = 0.0
         user_emb = self.user_embeddings(user) # (B, D)
diff --git a/gfml-rs/codes/CML.py b/gfml-rs/codes/CML.py
new file mode 100644
index 0000000..98f06a9
--- /dev/null
+++ b/gfml-rs/codes/CML.py
@@ -0,0 +1,193 @@
+import torch
+import numpy
+import functools
+import world
+
+import torch.nn.functional as F
+
+def doublewrap(function):
+    """
+    A decorator decorator, allowing to use the decorator to be used without
+    parentheses if not arguments are provided. All arguments must be optional.
+    """
+
+    @functools.wraps(function)
+    def decorator(*args, **kwargs):
+        if len(args) == 1 and len(kwargs) == 0 and callable(args[0]):
+            return function(args[0])
+        else:
+            return lambda wrapee: function(wrapee, *args, **kwargs)
+
+    return decorator
+
+
+class Multiply(torch.nn.Module):
+    def __init__(self, alpha):
+        super().__init__()
+        self.alpha = alpha
+
+    def forward(self, x):
+        x = torch.mul(x, self.alpha)
+        return x
+
+class CML(torch.nn.Module):
+    def __init__(self,
+                 config,
+                 dataset
+                 ):
+        '''
+                         n_users,
+                         n_items,
+                         embed_dim=20,
+                         features=None,
+                         margin=1.5,
+                         master_learning_rate=0.1,
+                         clip_norm=1.0,
+                         hidden_layer_dim=128,
+                         dropout_rate=0.2,
+                         feature_l2_reg=0.1,
+                         feature_projection_scaling_factor=0.5,
+                         use_rank_weight=True,
+                         use_cov_loss=True,
+                         cov_loss_weight=0.1
+         '''
+
+        super(CML, self).__init__()
+        self.n_users = dataset.n_users
+        self.n_items = dataset.m_items
+        self.embed_dim = config['recdim']
+
+        self.clip_norm = config['clip_norm']
+        self.margin = torch.tensor(config['margin']).to(world.device)
+        self.zero_tensor = torch.tensor([0.]).to(world.device)
+
+        if config['features'] is not None:
+            self.features = config['features']
+        else:
+            self.features = None
+
+        self.master_learning_rate = config['master_learning_rate']
+        self.hidden_layer_dim = config['hidden_layer_dim']
+        self.dropout_rate = config['dropout_rate']
+        self.feature_l2_reg = config['feature_l2_reg']
+        self.feature_projection_scaling_factor = config['feature_projection_scaling_factor']
+        self.use_rank_weight = config['use_rank_weight']
+        self.use_cov_loss = config['use_cov_loss']
+        self.cov_loss_weight = config['cov_loss_weight']
+
+        self.user_positive_items_pairs = None
+        self.negative_samples = None
+        self.score_user_ids = None
+
+        self.user_embeddings = torch.nn.Embedding(self.n_users, self.embed_dim)
+        self.item_embeddings = torch.nn.Embedding(self.n_items, self.embed_dim)
+
+        if config['features'] is not None:
+            self.feat_extract_model = torch.nn.Sequential(
+                torch.nn.Linear(self.features, self.hidden_layer_dim),
+                torch.nn.ReLU(),
+                torch.nn.Dropout(p=self.dropout_rate),
+                torch.nn.Linear(self.hidden_layer_dim, self.embed_dim),
+            )
+
+        self.f = torch.nn.Sigmoid()
+
+    def feature_loss(self):
+        loss = 0.0
+        if self.features is not None:
+            self.feat_extarc_model.add_module(name='feature_projection',
+                                              module=Multiply(self.feature_projection_scaling_factor))
+            self.feature_projection = self.feat_extract_model(self.features)
+
+            feature_distance = torch.sum(F.mse_loss(self.item_embeddings, self.feature_projection, reduction='none'),
+                                         dim=1)
+
+            loss += torch.sum(feature_distance) * self.feature_l2_reg
+
+        return loss
+
+    def covariance_loss(self):
+        X = torch.concat((self.item_embeddings, self.user_embeddings), dim=0)
+        n_rows = X.shape[0].to(torch.float32)
+        X = X - torch.mean(X, dim=0)
+        cov = torch.matmul(X, X.T) / n_rows
+
+        return cov.fill_diagonal_(0).sum() * self.cov_loss_weight
+
+    def clip_by_norm_op(self):
+        pass
+
+    def emb_distance(self, user_emb, item_emb):
+        return torch.sum(F.mse_loss(user_emb, item_emb, reduction='none'), dim=1)
+
+    def neg_emb_distance(self, user_emb, item_emb):
+        tensor_range = range(len(user_emb))
+        diff = user_emb.unsqueeze(dim=1) - item_emb.unsqueeze(dim=1)
+        sq_diff = diff.pow(2)
+        sum_sq_diff = sq_diff.sum(-1)[tensor_range, tensor_range, :]
+        return sum_sq_diff
+
+    def forward(self, users, items):
+        users = users.long()
+        items = items.long()
+        users_emb = self.user_embeddings(users)
+        items_emb = self.item_embeddings(items)
+        scores = torch.sum(users_emb*items_emb, dim=1)
+        return self.f(scores)
+
+    def loss(self, user, pos, neg):
+        loss_value = 0.0
+        user_emb = self.user_embeddings(user) # (B, D)
+        pos_emb = self.item_embeddings(pos) # (B, D)
+        neg_emb = self.item_embeddings(neg) # (B, N, D)
+
+        pos_dist = self.emb_distance(user_emb, pos_emb) # (B, )
+        neg_dist = self.emb_distance(user_emb, neg_emb)
+
+        # min_neg_dist = self.emb_distance(user_emb, neg_emb)
+        # neg_dist = self.neg_emb_distance(user_emb, neg_emb) # (B, N)
+        # min_neg_dist = torch.min(neg_dist, dim=1).values
+        # loss_per_pair = torch.maximum(pos_dist - min_neg_dist + self.margin, torch.tensor([0.]))
+        loss_per_pair = torch.maximum(pos_dist - neg_dist + self.margin, self.zero_tensor)
+
+        if self.use_rank_weight:
+            imposters = (pos_dist.view((-1,1)) - neg_dist + self.margin) > 0
+            rank = imposters.to(torch.float32).mean(1) * self.n_items
+            loss_per_pair *= torch.log(rank+1)
+
+        self.loss_e = torch.sum(loss_per_pair)
+        self.loss_f = self.feature_loss()
+
+        loss_value = self.loss_e + self.loss_f
+        if self.use_cov_loss:
+            loss_value += self.covariance_loss()
+
+        # embedding norm reg.
+        reg_loss = (1 / 2) * (user_emb.norm(2).pow(2) +
+                              pos_emb.norm(2).pow(2) +
+                              neg_emb.norm(2).pow(2)) / float(len(user_emb))
+
+        loss_value += reg_loss
+
+        return loss_value
+
+    def getUsersRating(self, users):
+        users = users.long()
+        users_emb = self.user_embeddings(users)
+        items_emb = self.item_embeddings.weight
+        scores = torch.matmul(users_emb, items_emb.t())
+        return self.f(scores)
+
+
+
+
+
+
+
+
+
+
+
+
+
+
diff --git a/gfml-rs/codes/model.py b/gfml-rs/codes/model.py
index 570c7bb..8bc730c 100644
--- a/gfml-rs/codes/model.py
+++ b/gfml-rs/codes/model.py
@@ -13,7 +13,6 @@ from dataloader import BasicDataset
 from torch import nn
 import numpy as np
 
-
 class BasicModel(nn.Module):
     def __init__(self):
         super(BasicModel, self).__init__()
@@ -340,7 +339,6 @@ class PureMF(BasicModel):
             loss = ((1-self.mix_ratio) * loss_bpr) + (self.mix_ratio * loss_gra)
             return loss
 
-
     def forward(self, users, items):
         users = users.long()
         items = items.long()
diff --git a/gfml-rs/codes/parse.py b/gfml-rs/codes/parse.py
index d6bafe0..1a7abb5 100644
--- a/gfml-rs/codes/parse.py
+++ b/gfml-rs/codes/parse.py
@@ -57,4 +57,17 @@ def parse_args():
     parser.add_argument('--ES', type=int, default=1)
     parser.add_argument('--infer_mode', type=str, default='mat')
     parser.add_argument('--lam_d', type=float, default=0.995)
+
+    # CML hypara
+    parser.add_argument('--features', default=None)
+    parser.add_argument('--margin', type=float, default=1.9)
+    parser.add_argument('--master_learning_rate', type=float, default=0.1)
+    parser.add_argument('--clip_norm', type=int, default=1)
+    parser.add_argument('--hidden_layer_dim', type=int, default=64)
+    parser.add_argument('--dropout_rate', type=float, default=0.2)
+    parser.add_argument('--feature_l2_reg', type=float, default=0.1)
+    parser.add_argument('--feature_projection_scaling_factor', type=float, default=0.5)
+    parser.add_argument('--use_rank_weight', action='store_true')
+    parser.add_argument('--use_cov_loss', action='store_true')
+    parser.add_argument('--cov_loss_weight', type=float, default=1.0)
     return parser.parse_args()
diff --git a/gfml-rs/codes/register.py b/gfml-rs/codes/register.py
index 23abd2e..2045a9e 100644
--- a/gfml-rs/codes/register.py
+++ b/gfml-rs/codes/register.py
@@ -2,7 +2,9 @@ import world
 import dataloader
 import model
 import utils
+
 from pprint import pprint
+from CML import CML
 
 if world.dataset in ['gowalla', 'yelp2018', 'amazon-book', 'dist_test', 'ml1m', 'amazon-music', 'amazon-baby']:
     dataset = dataloader.Loader(path="../data/"+world.dataset)
@@ -22,5 +24,6 @@ print('===========end===================')
 
 MODELS = {
     'mf': model.PureMF,
-    'lgn': model.LightGCN
+    'lgn': model.LightGCN,
+    'cml': CML
 }
\ No newline at end of file
diff --git a/gfml-rs/codes/utils.py b/gfml-rs/codes/utils.py
index 7f62347..d4631ff 100644
--- a/gfml-rs/codes/utils.py
+++ b/gfml-rs/codes/utils.py
@@ -56,6 +56,8 @@ class BPRLoss:
     def stageOne(self, users, pos, neg):
         if self.loss_mode in ["dot", "gravity", "mix", "bpr_gra", "mix_bpr"]:
             loss = self.model.bpr_loss(users, pos, neg)
+        elif self.loss_mode == "cml":
+            loss = self.model.loss(users, pos, neg)
         else:
             loss, reg_loss = self.model.bpr_loss(users, pos, neg)
             reg_loss = reg_loss * self.decay
@@ -130,7 +132,9 @@ def getFileName():
         file = f"mf-{world.dataset}-{world.config['latent_dim_rec']}.pth.tar"
     elif world.model_name == 'lgn':
         file = f"lgn-{world.dataset}-{world.config['lightGCN_n_layers']}-{world.config['latent_dim_rec']}.pth.tar"
-    return os.path.join(world.FILE_PATH,file)
+    elif world.model_name == 'cml':
+        file = f"cml--{world.dataset}-{world.config['latent_dim_rec']}.pth.tar"
+    return os.path.join(world.FILE_PATH, file)
 
 def minibatch(*tensors, **kwargs):
 
diff --git a/gfml-rs/codes/world.py b/gfml-rs/codes/world.py
index 682daa5..2bba15a 100644
--- a/gfml-rs/codes/world.py
+++ b/gfml-rs/codes/world.py
@@ -30,7 +30,7 @@ if not os.path.exists(FILE_PATH):
 
 config = {}
 all_dataset = ['lastfm', 'gowalla', 'yelp2018', 'amazon-book', 'dist_test', 'ml1m', 'amazon-music', 'amazon-baby']
-all_models  = ['mf', 'lgn']
+all_models  = ['mf', 'lgn', 'cml']
 # config['batch_size'] = 4096
 config['bpr_batch_size'] = args.bpr_batch
 config['latent_dim_rec'] = args.recdim
@@ -52,6 +52,20 @@ config['mass_mode'] = args.mass_mode
 config['lr_decay'] = args.lr_decay
 config['Early_Stopping'] = args.ES
 config['infer_mode'] = args.infer_mode
+config['recdim'] = args.recdim
+
+#------ CML hy-para ------
+config['features'] = args.features
+config['margin'] = args.margin
+config['master_learning_rate'] = args.master_learning_rate
+config['clip_norm'] = args.clip_norm
+config['hidden_layer_dim'] = args.hidden_layer_dim
+config['dropout_rate'] = args.dropout_rate
+config['feature_l2_reg'] = args.feature_l2_reg
+config['feature_projection_scaling_factor'] = args.feature_projection_scaling_factor
+config['use_rank_weight'] = args.use_rank_weight
+config['use_cov_loss'] = args.use_cov_loss
+config['cov_loss_weight'] = args.cov_loss_weight
 
 GPU = torch.cuda.is_available()
 device = torch.device(f'cuda:{args.gpu_id}' if GPU else "cpu")
