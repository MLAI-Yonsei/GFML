2023-06-29 16:41:04,314 INFO    MainThread:84798 [wandb_setup.py:_flush():68] Configure stats pid to 84798
2023-06-29 16:41:04,314 INFO    MainThread:84798 [wandb_setup.py:_flush():68] Loading settings from /home/hoyun/.config/wandb/settings
2023-06-29 16:41:04,314 INFO    MainThread:84798 [wandb_setup.py:_flush():68] Loading settings from /data1/deepdog/project/GFML/gfml-rs/codes/wandb/settings
2023-06-29 16:41:04,314 INFO    MainThread:84798 [wandb_setup.py:_flush():68] Loading settings from environment variables: {'_require_service': 'True'}
2023-06-29 16:41:04,314 INFO    MainThread:84798 [wandb_setup.py:_flush():68] Inferring run settings from compute environment: {'program_relpath': 'gfml-rs/codes/main.py', 'program': '/data1/deepdog/project/GFML/gfml-rs/codes/main.py'}
2023-06-29 16:41:04,314 INFO    MainThread:84798 [wandb_init.py:_log_setup():476] Logging user logs to /data1/deepdog/project/GFML/gfml-rs/codes/wandb/run-20230629_164104-2aw4r4jp/logs/debug.log
2023-06-29 16:41:04,315 INFO    MainThread:84798 [wandb_init.py:_log_setup():477] Logging internal logs to /data1/deepdog/project/GFML/gfml-rs/codes/wandb/run-20230629_164104-2aw4r4jp/logs/debug-internal.log
2023-06-29 16:41:04,315 INFO    MainThread:84798 [wandb_init.py:init():516] calling init triggers
2023-06-29 16:41:04,315 INFO    MainThread:84798 [wandb_init.py:init():519] wandb.init called with sweep_config: {}
config: {'bpr_batch': 2048, 'recdim': 64, 'layer': 3, 'lr': 0.0004, 'decay': 0.0001, 'dropout': 0, 'keepprob': 0.6, 'a_fold': 100, 'testbatch': 100, 'dataset': 'ml1m', 'path': './checkpoints', 'topks': '[5, 10, 20]', 'tensorboard': 0, 'comment': 'lgn', 'load': 0, 'epochs': 1000, 'multicore': 0, 'pretrain': 0, 'seed': 2020, 'model': 'cml', 'lamb': 2.0, 'mix_ratio': 0.4, 'loss_mode': 'mix_bpr', 'dist_mode': 'l2', 'exp_name': 'Apple', 'ema_on': 1, 'emb_norm': 1, 'weight_decay': 0.0003, 'lr_decay': 0.01, 'mass_mode': 'both', 'gpu_id': 1, 'ES': 1, 'infer_mode': 'mat', 'lam_d': 0.995, 'features': None, 'margin': 1.9, 'master_learning_rate': 0.1, 'clip_norm': 1, 'hidden_layer_dim': 64, 'dropout_rate': 0.2, 'feature_l2_reg': 0.1, 'feature_projection_scaling_factor': 0.5, 'use_rank_weight': True, 'use_cov_loss': False, 'cov_loss_weight': 1.0}
2023-06-29 16:41:04,315 INFO    MainThread:84798 [wandb_init.py:init():569] starting backend
2023-06-29 16:41:04,315 INFO    MainThread:84798 [wandb_init.py:init():573] setting up manager
2023-06-29 16:41:04,319 INFO    MainThread:84798 [backend.py:_multiprocessing_setup():102] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2023-06-29 16:41:04,325 INFO    MainThread:84798 [wandb_init.py:init():580] backend started and connected
2023-06-29 16:41:04,331 INFO    MainThread:84798 [wandb_init.py:init():658] updated telemetry
2023-06-29 16:41:04,356 INFO    MainThread:84798 [wandb_init.py:init():693] communicating run to backend with 60 second timeout
2023-06-29 16:41:05,178 INFO    MainThread:84798 [wandb_run.py:_on_init():2000] communicating current version
2023-06-29 16:41:05,271 INFO    MainThread:84798 [wandb_run.py:_on_init():2004] got version response upgrade_message: "wandb version 0.15.4 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"

2023-06-29 16:41:05,271 INFO    MainThread:84798 [wandb_init.py:init():728] starting run threads in backend
2023-06-29 16:41:09,340 INFO    MainThread:84798 [wandb_run.py:_console_start():1980] atexit reg
2023-06-29 16:41:09,340 INFO    MainThread:84798 [wandb_run.py:_redirect():1838] redirect: SettingsConsole.WRAP_RAW
2023-06-29 16:41:09,341 INFO    MainThread:84798 [wandb_run.py:_redirect():1903] Wrapping output streams.
2023-06-29 16:41:09,341 INFO    MainThread:84798 [wandb_run.py:_redirect():1925] Redirects installed.
2023-06-29 16:41:09,343 INFO    MainThread:84798 [wandb_init.py:init():765] run started, returning control to user process
2023-06-29 16:41:09,348 INFO    MainThread:84798 [wandb_run.py:_config_callback():1160] config_cb None None {'bpr_batch': 2048, 'recdim': 64, 'layer': 3, 'lr': 0.0004, 'decay': 0.0001, 'dropout': 0, 'keepprob': 0.6, 'a_fold': 100, 'testbatch': 100, 'dataset': 'ml1m', 'path': './checkpoints', 'topks': '[5, 10, 20]', 'tensorboard': 0, 'comment': 'lgn', 'load': 0, 'epochs': 1000, 'multicore': 0, 'pretrain': 0, 'seed': 2020, 'model': 'cml', 'lamb': 2.0, 'mix_ratio': 0.4, 'loss_mode': 'mix_bpr', 'dist_mode': 'l2', 'exp_name': 'Apple', 'ema_on': 1, 'emb_norm': 1, 'weight_decay': 0.0003, 'lr_decay': 0.01, 'mass_mode': 'both', 'gpu_id': 1, 'ES': 1, 'infer_mode': 'mat', 'lam_d': 0.995, 'features': None, 'margin': 1.9, 'master_learning_rate': 0.1, 'clip_norm': 1, 'hidden_layer_dim': 64, 'dropout_rate': 0.2, 'feature_l2_reg': 0.1, 'feature_projection_scaling_factor': 0.5, 'use_rank_weight': True, 'use_cov_loss': False, 'cov_loss_weight': 1.0}
