diff --git a/code/Procedure.py b/code/Procedure.py
index 7752ee9..4fc7e3e 100755
--- a/code/Procedure.py
+++ b/code/Procedure.py
@@ -11,10 +11,13 @@ import numpy as np
 import torch
 import utils
 import multiprocessing
+import wandb
 
 CORES = 1
 
 def Metric_train_original(args, dataset, model, loss_class, epoch, sampler, w=None):
+    utils.set_seed(args.seed)
+
     Recmodel = model
     Recmodel.train()
     metric = loss_class
@@ -28,7 +31,7 @@ def Metric_train_original(args, dataset, model, loss_class, epoch, sampler, w=No
         S = samples[0]
         num_items_per_user = samples[1]
 
-        metric_loss, reg_loss = metric.stageOne(S, num_items_per_user)
+        metric_loss, reg_loss, pos_loss, neg_loss = metric.stageOne(S, num_items_per_user)
 
         aver_metric_loss += metric_loss
         aver_reg_loss += reg_loss
@@ -38,6 +41,14 @@ def Metric_train_original(args, dataset, model, loss_class, epoch, sampler, w=No
     aver_metric_loss = aver_metric_loss / total_batch
     aver_reg_loss = aver_reg_loss / total_batch
 
+    wandb.log({
+        'epoch': epoch,
+        'Train_Metric_loss': aver_metric_loss,
+        'Train_Reg_loss': aver_reg_loss,
+        'Pos_loss': pos_loss,
+        'Neg_loss': neg_loss
+    })
+
     return f"aver metric loss{aver_metric_loss:.3e}, aver reg loss{aver_reg_loss:.3e}"
     
 def ndcg_func(ground_truths, ranks):
@@ -84,6 +95,7 @@ def test_one_batch(X):
             'ndcg':np.array(ndcg)}
             
 def Test(args, dataset, Recmodel, epoch, device, w=None, multicore=0):
+    utils.set_seed(args.seed)
 
     u_batch_size = args.testbatch
     testDict = dataset.testDict
@@ -168,4 +180,15 @@ def Test(args, dataset, Recmodel, epoch, device, w=None, multicore=0):
         if multicore == 1:
             pool.close()
         print(results)
+
+        wandb.log(
+            {
+                'Recall@5' : results['recall'][0],
+                'Recall@10' : results['recall'][1],
+                'Recall@20' : results['recall'][2],
+                'NDCG@5' : results['ndcg'][0],
+                'NDCG@10': results['ndcg'][1],
+                'NDCG@20': results['ndcg'][2],
+            }
+        )
         return results
diff --git a/code/__pycache__/Procedure.cpython-37.pyc b/code/__pycache__/Procedure.cpython-37.pyc
index a580e44..45204ce 100644
Binary files a/code/__pycache__/Procedure.cpython-37.pyc and b/code/__pycache__/Procedure.cpython-37.pyc differ
diff --git a/code/__pycache__/dataloader.cpython-37.pyc b/code/__pycache__/dataloader.cpython-37.pyc
index 7e64e66..1b492e9 100644
Binary files a/code/__pycache__/dataloader.cpython-37.pyc and b/code/__pycache__/dataloader.cpython-37.pyc differ
diff --git a/code/__pycache__/model.cpython-37.pyc b/code/__pycache__/model.cpython-37.pyc
index c30c896..857904f 100644
Binary files a/code/__pycache__/model.cpython-37.pyc and b/code/__pycache__/model.cpython-37.pyc differ
diff --git a/code/__pycache__/parse.cpython-37.pyc b/code/__pycache__/parse.cpython-37.pyc
index f31b20f..3a0a491 100644
Binary files a/code/__pycache__/parse.cpython-37.pyc and b/code/__pycache__/parse.cpython-37.pyc differ
diff --git a/code/__pycache__/utils.cpython-37.pyc b/code/__pycache__/utils.cpython-37.pyc
index 543f3c2..411f123 100644
Binary files a/code/__pycache__/utils.cpython-37.pyc and b/code/__pycache__/utils.cpython-37.pyc differ
diff --git a/code/bashes/gfml_books.sh b/code/bashes/gfml_books.sh
new file mode 100644
index 0000000..df100e9
--- /dev/null
+++ b/code/bashes/gfml_books.sh
@@ -0,0 +1,11 @@
+#!/bin/bash
+DATA="amazon-book"
+GPU=3
+
+for LR in 1e-2 1e-3 1e-4 1e-5 1e-6
+do
+for LAM in 1e-2 1e-1 10e-1 30e-1 50e-1
+do
+python main.py --gfml --dataset $DATA --gpu_id $GPU --lr $LR --lambd $LAM
+done
+done
\ No newline at end of file
diff --git a/code/bashes/gfml_grocery.sh b/code/bashes/gfml_grocery.sh
new file mode 100644
index 0000000..04f25dd
--- /dev/null
+++ b/code/bashes/gfml_grocery.sh
@@ -0,0 +1,17 @@
+#!/bin/bash
+DATA="amazon-grocery"
+GPU=2
+
+for LR in 1e-2 1e-4 1e-6
+do
+for LAM in 1e-2 10e-1 50e-1
+do
+for lamP in 1.5 1.2 1.0
+do
+for lamN in 1.0 0.9 0.5
+do
+python main.py --gfml --dataset $DATA --gpu_id $GPU --lr $LR --lambd $LAM --lamb_p $lamP --lamb_n $lamN
+done
+done
+done
+done
\ No newline at end of file
diff --git a/code/bashes/gfml_music.sh b/code/bashes/gfml_music.sh
new file mode 100644
index 0000000..ee32aba
--- /dev/null
+++ b/code/bashes/gfml_music.sh
@@ -0,0 +1,17 @@
+#!/bin/bash
+DATA="amazon-digital-music"
+GPU=1
+
+for LR in 1e-2 1e-4 1e-6
+do
+for LAM in 1e-2 10e-1 50e-1
+do
+for lamP in 1.5 1.2 1.0
+do
+for lamN in 1.0 0.9 0.5
+do
+python main.py --gfml --dataset $DATA --gpu_id $GPU --lr $LR --lambd $LAM --lamb_p $lamP --lamb_n $lamN
+done
+done
+done
+done
\ No newline at end of file
diff --git a/code/bashes/gfml_yelp.sh b/code/bashes/gfml_yelp.sh
new file mode 100644
index 0000000..640ab8c
--- /dev/null
+++ b/code/bashes/gfml_yelp.sh
@@ -0,0 +1,11 @@
+#!/bin/bash
+DATA="yelp"
+GPU=4
+
+for LR in 1e-2 1e-3 1e-4 1e-5 1e-6
+do
+for LAM in 1e-2 1e-1 10e-1 30e-1 50e-1
+do
+python main.py --gfml --dataset $DATA --gpu_id $GPU --lr $LR --lambd $LAM --multicore 0
+done
+done
\ No newline at end of file
diff --git a/code/bashes/mix_grocery.sh b/code/bashes/mix_grocery.sh
new file mode 100644
index 0000000..674ab65
--- /dev/null
+++ b/code/bashes/mix_grocery.sh
@@ -0,0 +1,20 @@
+#!/bin/bash
+DATA="amazon-grocery"
+GPU=2
+
+for LR in 1e-3 1e-4 1e-2
+do
+for LAM in 50e-1 10e-1 1e-2
+do
+for lamP in 1.0 1.2 1.5
+do
+for lamN in 0.5 0.9 1.0
+do
+for MIX in 0.7 0.5 0.3
+do
+python main.py --mix --mix_ratio $MIX --dataset $DATA --gpu_id $GPU --lr $LR --lambd $LAM --lamb_p $lamP --lamb_n $lamN --lambp 6.5 --lambn -0.5
+done
+done
+done
+done
+done
\ No newline at end of file
diff --git a/code/bashes/mix_music.sh b/code/bashes/mix_music.sh
new file mode 100644
index 0000000..7de0774
--- /dev/null
+++ b/code/bashes/mix_music.sh
@@ -0,0 +1,20 @@
+#!/bin/bash
+DATA="amazon-digital-music"
+GPU=0
+
+for LR in 1e-2
+do
+for LAM in 1e-2
+do
+for lamP in 2.0 1.7 1.5 1.3 1.0
+do
+for lamN in 1.0 0.9 0.8 0.7 0.6
+do
+for MIX in 0.7
+do
+python main.py --mix --mix_ratio $MIX --dataset $DATA --gpu_id $GPU --lr $LR --lambd $LAM --lamb_p $lamP --lamb_n $lamN --lambp 6.5 --lambn -0.5
+done
+done
+done
+done
+done
\ No newline at end of file
diff --git a/code/dataloader.py b/code/dataloader.py
index 0efbf73..66dc1bf 100755
--- a/code/dataloader.py
+++ b/code/dataloader.py
@@ -16,6 +16,11 @@ from torch.utils.data import Dataset
 from scipy.sparse import csr_matrix
 import scipy.sparse as sp
 from time import time
+import utils
+from parse import parse_args
+
+args = parse_args()
+utils.set_seed(args.seed)
 
 def binarize_dataset(threshold, training_users, training_items, training_ratings):
     for i in range(len(training_ratings)):
diff --git a/code/main.py b/code/main.py
index 5893906..e947600 100755
--- a/code/main.py
+++ b/code/main.py
@@ -5,17 +5,27 @@ from os.path import join
 from parse import parse_args
 import Procedure
 # from tensorboardX import SummaryWriter
-from torch.utils.tensorboard import SummaryWriter
+# from torch.utils.tensorboard import SummaryWriter
 import time
 import torch
 import utils
+import wandb
 
 if __name__ == '__main__':
-
     # set seed
     args = parse_args()
+
+    if args.gfml:
+        args.mix = False
+    elif args.mix:
+        args.gfml = False
+
     utils.set_seed(args.seed)
-    device = torch.device('cuda' if torch.cuda.is_available() else "cpu")
+    if torch.cuda.is_available():
+        print("CUDA is avaiable")
+    else:
+        print("CUDA is not available")
+    device = torch.device(f'cuda:{args.gpu_id}' if torch.cuda.is_available() else "cpu")
 
     # create model and load dataset
     dataset = Loader(args, device, path="../data/" + args.dataset)
@@ -26,6 +36,21 @@ if __name__ == '__main__':
     # save/load file
     weight_file = utils.getFileName(args)
     print(f"load and save to {weight_file}")
+
+    wandb.login()
+    if args.gfml:
+        wandb.init(project='GFML_Revision_MCL',
+                   name=f'{weight_file}',
+                   config=args)
+    else:
+        wandb.init(project='GFML_Revision_MCL',
+                   name=f'{weight_file}',
+                   config=args)
+
+    # wandb.config.update(args)
+
+    wandb.watch(model)
+
     if args.load:
         try:
             model.load_state_dict(torch.load(weight_file, map_location=torch.device('cpu')))
@@ -35,9 +60,10 @@ if __name__ == '__main__':
 
     # init tensorboard
     if args.tensorboard:
-        w : SummaryWriter = SummaryWriter(
-                                join("./runs", time.strftime("%m-%d-%Hh%Mm%Ss-"))
-                            )
+        # w : SummaryWriter = SummaryWriter(
+        #                         join("./runs", time.strftime("%m-%d-%Hh%Mm%Ss-"))
+        #                     )
+        w = None
     else:
         w = None
 
@@ -48,6 +74,16 @@ if __name__ == '__main__':
     try:
         topks = eval(args.topks)
         best_result = np.zeros(2*len(topks))
+        TOTAL_BEST = 0.0
+        BEST_NDCG10 = 1e-10
+
+        wandb.log(
+            {
+                'TOTAL_BEST_METRIC': TOTAL_BEST,
+                'BEST_NDCG@10': BEST_NDCG10
+            }
+        )
+
         for epoch in range(1, args.epochs+1):
             print(f'Epoch {epoch}/{args.epochs}')
             start = time.time()
@@ -55,7 +91,33 @@ if __name__ == '__main__':
                 result = Procedure.Test(args, dataset, model, epoch, device, w, args.multicore)
                 if np.sum(np.append(result['recall'], result['ndcg'])) > np.sum(best_result):
                     best_result = np.append(result['recall'], result['ndcg'])
+                    TOTAL_BEST = np.sum(best_result)
                     torch.save(model.state_dict(), weight_file)
+                    wandb.log(
+                        {
+                            'Recall@5_total_best' : result['recall'][0],
+                            'Recall@10_total_best': result['recall'][1],
+                            'Recall@20_total_best': result['recall'][2],
+                            'ndcg@5_total_best': result['ndcg'][0],
+                            'ndcg@10_total_best': result['ndcg'][1],
+                            'ndcg@20_total_best': result['ndcg'][2],
+                            'TOTAL_BEST_METRIC': TOTAL_BEST
+                        }
+                    )
+                if result['ndcg'][1] > BEST_NDCG10:
+                    BEST_NDCG10 = result['ndcg'][1]
+                    wandb.log(
+                        {
+                            'EPOCH_ndcg_best' : epoch,
+                            'Recall@5_ndcg_best': result['recall'][0],
+                            'Recall@10_ndcg_best': result['recall'][1],
+                            'Recall@20_ndcg_best': result['recall'][2],
+                            'ndcg@5_ndcg_best': result['ndcg'][0],
+                            'ndcg@10_ndcg_best': result['ndcg'][1],
+                            'ndcg@20_ndcg_best': result['ndcg'][2],
+                            'BEST_NDCG@10': BEST_NDCG10
+                        }
+                    )
                 print("Best so far:", best_result)
 
             output_information = Procedure.Metric_train_original(args, dataset, model, metric, epoch, sampler, w)
@@ -66,9 +128,37 @@ if __name__ == '__main__':
         result = Procedure.Test(args, dataset, model, epoch, device, w, args.multicore)
         if np.sum(np.append(result['recall'], result['ndcg'])) > np.sum(best_result):
             best_result = np.append(result['recall'], result['ndcg'])
+            TOTAL_BEST = np.sum(best_result)
             torch.save(model.state_dict(), weight_file)
+            wandb.log(
+                {
+                    'Recall@5_total_best': result['recall'][0],
+                    'Recall@10_total_best': result['recall'][1],
+                    'Recall@20_total_best': result['recall'][2],
+                    'ndcg@5_total_best': result['ndcg'][0],
+                    'ndcg@10_total_best': result['ndcg'][1],
+                    'ndcg@20_total_best': result['ndcg'][2],
+                    'TOTAL_BEST_METRIC': TOTAL_BEST
+                }
+            )
+        if result['ndcg'][1] > BEST_NDCG10:
+            BEST_NDCG10 = result['ndcg'][1]
+            wandb.log(
+                {
+                    'EPOCH_ndcg_best': epoch,
+                    'Recall@5_ndcg_best': result['recall'][0],
+                    'Recall@10_ndcg_best': result['recall'][1],
+                    'Recall@20_ndcg_best': result['recall'][2],
+                    'ndcg@5_ndcg_best': result['ndcg'][0],
+                    'ndcg@10_ndcg_best': result['ndcg'][1],
+                    'ndcg@20_ndcg_best': result['ndcg'][2],
+                    'BEST_NDCG@10': BEST_NDCG10
+                }
+            )
         print("Best overall:", best_result)
 
+        wandb.finish()
+
     finally:
         sampler.close()
         if args.tensorboard:
diff --git a/code/model.py b/code/model.py
index 8a705a0..84b6ed4 100755
--- a/code/model.py
+++ b/code/model.py
@@ -12,6 +12,7 @@ from torch import nn
 import numpy as np
 import random
 import itertools
+import wandb
 
 class LightGCN(nn.Module):
     def __init__(self, args, device, dataset):
@@ -33,6 +34,15 @@ class LightGCN(nn.Module):
         nn.init.xavier_uniform_(self.embedding_user.weight, gain=1)
         nn.init.xavier_uniform_(self.embedding_item.weight, gain=1)
 
+        if self.args.gfml or self.args.mix:
+            self.mass_u = nn.Embedding(self.num_users, 1)
+            self.mass_i = nn.Embedding(self.num_items, 1)
+            nn.init.xavier_normal_(self.mass_u.weight)
+            nn.init.xavier_normal_(self.mass_i.weight)
+
+            self.relu = nn.ReLU()
+            self.lambd = self.args.lambd
+
         self.f = nn.Sigmoid()
         self.Graph = self.dataset.getSparseGraph()
 
@@ -114,6 +124,25 @@ class LightGCN(nn.Module):
         neg_emb_ego = self.embedding_item(neg_items)
         return users_emb, pos_emb, neg_emb, users_emb_ego, pos_emb_ego, neg_emb_ego
 
+    def gravity(self, users, pos_items, neg_items, pos_dist, neg_dist):
+        # user & pos_items
+        up_mass = torch.log(self.relu(self.mass_u(users)) + 1) + torch.log(self.relu(self.mass_i(pos_items)) + 1)
+        up_dist = self.lambd * torch.log(pos_dist + 1)
+        up_loss = up_dist - up_mass.squeeze()
+
+        # user & neg_items
+        un_mass = torch.log(self.relu(self.mass_u(users)) + 1) + torch.log(self.relu(self.mass_i(neg_items)) + 1)
+        un_dist = self.lambd * torch.log(neg_dist + 1)
+        un_loss = un_mass.squeeze() - un_dist
+
+        if self.args.gfml_opt == 1:
+            # Gravity only pos-item<->user
+            metric_loss = torch.mean(up_loss)
+        else:
+            metric_loss = self.args.lamb_p*torch.mean(up_loss) + self.args.lamb_n*torch.mean(un_loss)
+
+        return torch.mean(metric_loss), torch.mean(up_loss), torch.mean(un_loss)
+
     def loss(self, S, num_items_per_user):
         users = torch.Tensor(S[:, 0]).long()
         pos_items = torch.Tensor(S[:, 1]).long()
@@ -136,37 +165,106 @@ class LightGCN(nn.Module):
         distance_to_neg_items = torch.sum((users_emb.unsqueeze(-1) - neg_emb.transpose(-2, -1)) ** 2, 1)
         min_neg_per_item = distance_to_neg_items.min(1)[0]
 
-        # mining
-        start_idx = 0
-        pos_lengths = []
-        neg_length = []
-        for i in num_items_per_user:
-
-            max_pos_length = pos_distances[start_idx: start_idx+i].max()
-            pos_lengths.append(max_pos_length)
-            
-            min_neg_length = min_neg_per_item[start_idx: start_idx+i].min()
-            neg_length.append(min_neg_length)
-            
-            start_idx += i
-
-        num_items_per_user = torch.LongTensor(num_items_per_user)
-
-        pos_lengths = torch.repeat_interleave(torch.tensor(pos_lengths), num_items_per_user)
-        pos_lengths = pos_lengths.to(self.device)
-        neg_length = torch.repeat_interleave(torch.tensor(neg_length), num_items_per_user)
-        neg_length = neg_length.to(self.device)
-
-        # negative mining using max pos length
-        neg_idx = (distance_to_neg_items - (self.args.margin + pos_lengths.unsqueeze(-1))) >= 0
-        distance_to_neg_items = distance_to_neg_items + torch.where(neg_idx, float('inf'), 0.)
-
-        # positive mining using min neg length
-        pos_idx = (pos_distances - (neg_length - self.args.margin)) <= 0
-        pos_distances = pos_distances + torch.where(pos_idx, -float('inf'), 0.)
-
-        # compute loss
-        neg_loss = 1.0 / self.args.beta * torch.log(1 + torch.sum(torch.exp(-self.args.beta * (distance_to_neg_items + self.args.lamb_n)))/self.args.batch_size)
-        pos_loss = 1.0 / self.args.alpha * torch.log(1 + torch.sum(torch.exp(self.args.alpha * (pos_distances + self.args.lamb_p)))/self.args.batch_size)
-        
-        return (neg_loss+pos_loss), reg_loss
+        if self.args.gfml:
+            min_neg_items = neg_items[
+                torch.arange(neg_items.size(0)).unsqueeze(1), distance_to_neg_items.min(1)[1].unsqueeze(-1)].squeeze()
+
+            minnegEmb = negEmb0[torch.arange(negEmb0.size(0)).unsqueeze(1),
+                        distance_to_neg_items.min(1)[1].unsqueeze(-1), :].squeeze()
+
+            reg_loss = (1 / 2) * (userEmb0.norm(2).pow(2) + posEmb0.norm(2).pow(2)) / float(len(users)) + \
+                       (1 / 2) * minnegEmb.norm(2).pow(2) / float(len(users))
+
+            metric_loss, pos_loss, neg_loss = self.gravity(users=users, pos_items=pos_items, neg_items=min_neg_items,
+                                                           pos_dist=pos_distances, neg_dist=min_neg_per_item)
+
+            return metric_loss, reg_loss, pos_loss, neg_loss
+
+        elif self.args.mix:
+            # gfml
+            min_neg_items = neg_items[
+                torch.arange(neg_items.size(0)).unsqueeze(1), distance_to_neg_items.min(1)[1].unsqueeze(-1)].squeeze()
+
+            minnegEmb = negEmb0[torch.arange(negEmb0.size(0)).unsqueeze(1),
+                        distance_to_neg_items.min(1)[1].unsqueeze(-1), :].squeeze()
+
+            # reg_loss = (1 / 2) * (userEmb0.norm(2).pow(2) + posEmb0.norm(2).pow(2)) / float(len(users)) + \
+            #            (1 / 2) * minnegEmb.norm(2).pow(2) / float(len(users))
+
+            gfml_loss, gfml_pos_loss, gfml_neg_loss = self.gravity(users=users, pos_items=pos_items, neg_items=min_neg_items,
+                                                                          pos_dist=pos_distances, neg_dist=min_neg_per_item)
+
+            # mcl
+            start_idx = 0
+            pos_lengths = []
+            neg_length = []
+            for i in num_items_per_user:
+                max_pos_length = pos_distances[start_idx: start_idx + i].max()
+                pos_lengths.append(max_pos_length)
+
+                min_neg_length = min_neg_per_item[start_idx: start_idx + i].min()
+                neg_length.append(min_neg_length)
+
+                start_idx += i
+
+            num_items_per_user = torch.LongTensor(num_items_per_user)
+
+            pos_lengths = torch.repeat_interleave(torch.tensor(pos_lengths), num_items_per_user)
+            pos_lengths = pos_lengths.to(self.device)
+            neg_length = torch.repeat_interleave(torch.tensor(neg_length), num_items_per_user)
+            neg_length = neg_length.to(self.device)
+
+            # negative mining using max pos length
+            neg_idx = (distance_to_neg_items - (self.args.margin + pos_lengths.unsqueeze(-1))) >= 0
+            distance_to_neg_items = distance_to_neg_items + torch.where(neg_idx, float('inf'), 0.)
+
+            # positive mining using min neg length
+            pos_idx = (pos_distances - (neg_length - self.args.margin)) <= 0
+            pos_distances = pos_distances + torch.where(pos_idx, -float('inf'), 0.)
+
+            # compute loss
+            neg_loss = 1.0 / self.args.beta * torch.log(1 + torch.sum(
+                torch.exp(-self.args.beta * (distance_to_neg_items + self.args.lambn))) / self.args.batch_size)
+            pos_loss = 1.0 / self.args.alpha * torch.log(
+                1 + torch.sum(torch.exp(self.args.alpha * (pos_distances + self.args.lambp))) / self.args.batch_size)
+
+            mcl_loss = neg_loss + pos_loss
+
+            metric_loss = (1-self.args.mix_ratio) * mcl_loss + self.args.mix_ratio * gfml_loss
+
+            return metric_loss, reg_loss, pos_loss, neg_loss
+        else:
+            # mining
+            start_idx = 0
+            pos_lengths = []
+            neg_length = []
+            for i in num_items_per_user:
+
+                max_pos_length = pos_distances[start_idx: start_idx+i].max()
+                pos_lengths.append(max_pos_length)
+
+                min_neg_length = min_neg_per_item[start_idx: start_idx+i].min()
+                neg_length.append(min_neg_length)
+
+                start_idx += i
+
+            num_items_per_user = torch.LongTensor(num_items_per_user)
+
+            pos_lengths = torch.repeat_interleave(torch.tensor(pos_lengths), num_items_per_user)
+            pos_lengths = pos_lengths.to(self.device)
+            neg_length = torch.repeat_interleave(torch.tensor(neg_length), num_items_per_user)
+            neg_length = neg_length.to(self.device)
+
+            # negative mining using max pos length
+            neg_idx = (distance_to_neg_items - (self.args.margin + pos_lengths.unsqueeze(-1))) >= 0
+            distance_to_neg_items = distance_to_neg_items + torch.where(neg_idx, float('inf'), 0.)
+
+            # positive mining using min neg length
+            pos_idx = (pos_distances - (neg_length - self.args.margin)) <= 0
+            pos_distances = pos_distances + torch.where(pos_idx, -float('inf'), 0.)
+
+            # compute loss
+            neg_loss = 1.0 / self.args.beta * torch.log(1 + torch.sum(torch.exp(-self.args.beta * (distance_to_neg_items + self.args.lambn)))/self.args.batch_size)
+            pos_loss = 1.0 / self.args.alpha * torch.log(1 + torch.sum(torch.exp(self.args.alpha * (pos_distances + self.args.lambp)))/self.args.batch_size)
+
+            return (neg_loss+pos_loss), reg_loss, pos_loss, neg_loss
\ No newline at end of file
diff --git a/code/parse.py b/code/parse.py
index cc44dbf..344b375 100755
--- a/code/parse.py
+++ b/code/parse.py
@@ -20,7 +20,7 @@ def parse_args():
     parser.add_argument('--topks', nargs='?',default="[5, 10, 20]",
                         help="@k test list")
 
-    parser.add_argument('--tensorboard', type=int,default=1,
+    parser.add_argument('--tensorboard', type=int,default=0,
                         help="enable tensorboard")
     parser.add_argument('--load', type=int, default=0)
     parser.add_argument('--multicore', type=int, default=1, help='whether we use multiprocessing or not in test')
@@ -54,7 +54,19 @@ def parse_args():
     parser.add_argument('--margin', type=float, default=1.0, help="margin for the metric loss")
     parser.add_argument('--alpha', type=float, default=1.25, help="pos, alpha for mul loss")
     parser.add_argument('--beta', type=float, default=5.0, help="neg, beta for mul loss")
-    parser.add_argument('--lamb_p', type=float, default=6.5, help="negative threshold")
-    parser.add_argument('--lamb_n', type=float, default=-0.5, help="positive threshold")
+    parser.add_argument('--lambp', type=float, default=6.5, help="negative threshold")
+    parser.add_argument('--lambn', type=float, default=-0.5, help="positive threshold")
+
+    # GFML
+    parser.add_argument('--gfml', action='store_true')
+    parser.add_argument('--gfml_opt', type=int, default=0)
+    parser.add_argument('--mix', action='store_true')
+    parser.add_argument('--lambd', type=float, default=1.0)
+    parser.add_argument('--gpu_id', type=int, default=1)
+    parser.add_argument('--lamb_p', type=float, default=1.0)
+    parser.add_argument('--lamb_n', type=float, default=1.0)
+    parser.add_argument('--mix_ratio', type=float, default=0.5)
+    parser.add_argument('--ema', action='store_true')
+    parser.add_argument('--ema_decay', type=float, default=0.995)
 
     return parser.parse_args()
\ No newline at end of file
diff --git a/code/utils.py b/code/utils.py
index 9c8b0f5..7ebcf69 100755
--- a/code/utils.py
+++ b/code/utils.py
@@ -12,16 +12,31 @@ import random
 import os
 import torch
 from torch import nn, optim
+from torch_ema import ExponentialMovingAverage
 
 class MetricLoss:
     def __init__(self, model, args):
         self.model = model
         self.args = args
-        self.opt = optim.Adam((model.embedding_user.weight, model.embedding_item.weight), lr=self.args.lr)
 
-    def stageOne(self, S, num_items_per_user):
+        if args.gfml or args.mix:
+            if args.ema:
+                self.opt = optim.Adam(
+                    (model.embedding_user.weight, model.embedding_item.weight),
+                    lr=self.args.lr)
+                self.ema = ExponentialMovingAverage((model.mass_u.weight, model.mass_i.weight), decay=args.ema_decay)
+            else:
+                self.opt = optim.Adam(
+                    (model.embedding_user.weight, model.embedding_item.weight, model.mass_u.weight, model.mass_i.weight),
+                    lr=self.args.lr)
+
+        else:
+            self.opt = optim.Adam(
+                (model.embedding_user.weight, model.embedding_item.weight),
+                lr=self.args.lr)
 
-        metric_loss, reg_loss = self.model.loss(S, num_items_per_user)
+    def stageOne(self, S, num_items_per_user):
+        metric_loss, reg_loss, pos_loss, neg_loss = self.model.loss(S, num_items_per_user)
         reg_loss = reg_loss * self.args.decay
         loss = metric_loss + reg_loss
 
@@ -29,7 +44,10 @@ class MetricLoss:
         loss.backward()
         self.opt.step()
 
-        return metric_loss.cpu().item(), reg_loss.cpu().item()
+        if self.args.ema:
+            self.ema.update()
+
+        return metric_loss.cpu().item(), reg_loss.cpu().item(), pos_loss, neg_loss
 
 class WarpSampler(object):
     """
@@ -99,16 +117,20 @@ def UniformSample_original(allPos, num_users, num_items, batch_size, neg_k, resu
             result_queue.put((user_triples, num_items_per_user))
 
 def set_seed(seed):
-    np.random.seed(seed)   
+    torch.manual_seed(seed)
+    random.seed(seed)
+    np.random.seed(seed)
+    os.environ["PYTHONHASHSEED"] = str(seed)
     if torch.cuda.is_available():
         torch.cuda.manual_seed(seed)
         torch.cuda.manual_seed_all(seed)
-    torch.manual_seed(seed)
+        # torch.backends.cudnn.deterministic = True
+        # torch.backends.cudnn.benchmark = False
 
 def getFileName(args):
-    path = "./checkpoints"
-    file = f"{args.dataset}-{args.layer}-{args.dim}-{args.alpha}-{args.beta}-{args.lamb_p}-{args.lamb_n}.pth.tar"
-    return os.path.join(path,file)
+    path = "../checkpoints"
+    file = f"{args.dataset}-gfml-{str(args.gfml)}-{args.lr}-{args.lambd}.pth.tar"
+    return os.path.join(path, file)
 
 def minibatch(*tensors, **kwargs):
 
